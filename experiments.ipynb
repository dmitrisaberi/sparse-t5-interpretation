{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define the dataset name and version\n",
    "dataset_name = \"squad\"\n",
    "# dataset_version = \"wikitext-103-raw-v1\"\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(dataset_name) #, dataset_version)\n",
    "train_dataset = dataset['train']\n",
    "valid_dataset = dataset['validation']\n",
    "\n",
    "# load train and validation split of squad\n",
    "# train_dataset  = nlp.load_dataset('squad', split=nlp.Split.TRAIN)\n",
    "# valid_dataset = nlp.load_dataset('squad', split=nlp.Split.VALIDATION)\n",
    "\n",
    "\n",
    "# Define the device (GPU if available)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the T5 model and tokenizer\n",
    "# model = T5ForConditionalGeneration.from_pretrained('t5-base').to(device)\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "from transformers import  AutoTokenizer, AutoModelWithLMHead, pipeline\n",
    "model_name = \"MaRiOrOsSi/t5-base-finetuned-question-answering\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def getActivation(name):\n",
    "  # the hook signature\n",
    "    def hook(model, input, output):\n",
    "        if name not in activation.keys():\n",
    "            activation[name] = [output.detach()]\n",
    "        else:\n",
    "            activation[name].append(output.detach())\n",
    "    return hook\n",
    "\n",
    "hooks = []\n",
    "for name, module in model.named_modules():\n",
    "    if \"act\" in name:\n",
    "        hooks.append(module.register_forward_hook(getActivation(name)))\n",
    "\n",
    "for hook in hooks:\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What my mother's name?\"\n",
    "context = \"My mother's name is Ann.\"\n",
    "input = f\"question: {question} context: {context}\"\n",
    "encoded_input = tokenizer([input],\n",
    "                             return_tensors='pt',\n",
    "                             max_length=512,\n",
    "                             truncation=True)\n",
    "output = model.generate(input_ids = encoded_input.input_ids,\n",
    "                            attention_mask = encoded_input.attention_mask)\n",
    "print(output.size())\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0abf3127efe1190c166efd1914d950e12a1420cbce56b58399667c772c7926e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define the dataset name and version\n",
    "dataset_name = \"squad\"\n",
    "# dataset_version = \"wikitext-103-raw-v1\"\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(dataset_name) #, dataset_version)\n",
    "train_dataset = dataset['train']\n",
    "valid_dataset = dataset['validation']\n",
    "\n",
    "# load train and validation split of squad\n",
    "# train_dataset  = nlp.load_dataset('squad', split=nlp.Split.TRAIN)\n",
    "# valid_dataset = nlp.load_dataset('squad', split=nlp.Split.VALIDATION)\n",
    "\n",
    "\n",
    "# Define the device (GPU if available)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the T5 model and tokenizer\n",
    "# model = T5ForConditionalGeneration.from_pretrained('t5-base').to(device)\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "from transformers import  AutoTokenizer, AutoModelWithLMHead, pipeline\n",
    "model_name = \"MaRiOrOsSi/t5-base-finetuned-question-answering\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getActivation(name, activation):\n",
    "  # the hook signature\n",
    "    def hook(model, input, output):\n",
    "        if name not in activation.keys():\n",
    "            activation[name] = [output.detach()]\n",
    "        else:\n",
    "            activation[name].append(output.detach())\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING CELL: put in one input, test for similarity between output length and number of elements in \"activation\"\n",
    "question = \"What my mother's name?\"\n",
    "context = \"My mother's name is Ann Marjorie Saberi.\"\n",
    "input = f\"question: {question} context: {context}\"\n",
    "encoded_input = tokenizer([input],\n",
    "                             return_tensors='pt',\n",
    "                             max_length=512,\n",
    "                             truncation=True)\n",
    "# Register hooks\n",
    "handles = []\n",
    "activation = {}\n",
    "for name, module in model.named_modules():\n",
    "    if \"act\" in name:\n",
    "        handles.append(module.register_forward_hook(getActivation(name, activation)))\n",
    "\n",
    "output = model.generate(input_ids = encoded_input.input_ids,\n",
    "                            attention_mask = encoded_input.attention_mask)\n",
    "print(output.size())\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output)\n",
    "\n",
    "# Remove hooks (we can only use them once!)\n",
    "for handle in handles:\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SQuAD dataset\n",
    "dataset = load_dataset(\"squad\", split=\"validation\")\n",
    "\n",
    "# initialize sparsities dict\n",
    "sparsities = {}\n",
    "\n",
    "# Iterate over the dataset and feed it into the model\n",
    "with torch.no_grad():\n",
    "    for example in dataset:\n",
    "        # Get the input and target text from the example\n",
    "        input_text = f\"question: {example['question']} context: {example['context']}\"\n",
    "        target_text = example[\"answers\"][\"text\"][0]\n",
    "\n",
    "        # Register hooks\n",
    "        handles = []\n",
    "        activation = {}\n",
    "        for name, module in model.named_modules():\n",
    "            if \"act\" in name:\n",
    "                handles.append(module.register_forward_hook(getActivation(name, activation)))\n",
    "\n",
    "        # Tokenize the input and target text\n",
    "        input_ids = tokenizer.encode(input_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        target_ids = tokenizer.encode(target_text, padding=True, truncation=True, max_length=32, return_tensors=\"pt\")\n",
    "\n",
    "        # Generate the output from the model\n",
    "        output_ids = model.generate(input_ids)\n",
    "\n",
    "        # Compute sparsities, after forward pass\n",
    "        for key in activation.keys():\n",
    "            hidden_states = torch.cat(activation[key])\n",
    "            if key not in sparsities.keys():\n",
    "                sparsities[key] = [len(torch.nonzero(hidden_states))/torch.numel(hidden_states)]\n",
    "            else:\n",
    "                sparsities[key].append(len(torch.nonzero(hidden_states))/torch.numel(hidden_states))\n",
    "\n",
    "        # Remove hooks (we can only use them once!)\n",
    "        for handle in handles:\n",
    "            handle.remove()\n",
    "\n",
    "        # Decode the output and print the results\n",
    "      #  output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "      #  print(\"Input Text:\", input_text)\n",
    "      #  print(\"Target Text:\", target_text)\n",
    "      #  print(\"Generated Text:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "avg_sparsities = {}\n",
    "for key in sparsities.keys():\n",
    "    s = np.array(sparsities[key])\n",
    "    avg_sparsities[key] = np.mean(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "names = list(avg_sparsities.keys())\n",
    "shortened_names = []\n",
    "for i in range(24):\n",
    "    if i < 12:\n",
    "        shortened_names.append(\"e\" + str(i+1))\n",
    "    else:\n",
    "        shortened_names.append(\"d\" + str(i%12+1))\n",
    "values = list(avg_sparsities.values())\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(len(avg_sparsities)), values, tick_label=shortened_names)\n",
    "plt.title(\"Average sparsity of activation layers\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0abf3127efe1190c166efd1914d950e12a1420cbce56b58399667c772c7926e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

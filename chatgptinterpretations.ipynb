{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pmcEb3_WxbTB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "obj = pd.read_pickle(r'specific-token-100-200-activating-prompts.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmQmuvXCyCcc",
        "outputId": "c59eb8b3-8ef2-46a4-d81c-ab4a24d3a7f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "\n",
        "openai.api_key = \"\"\n",
        "context = \"Please analyze the following list of tokens and identify whether they exhibit any semantic or syntactic themes. If so, respond 'Yes: ' followed by a list of no more than three themes in under ten words. If not, simply respond 'No'. (For example: 'Pizza, pasta, spaghetti, roads, bridges, ninety-seven' -> 'Yes: mostly italian food and infrastructure', 'quixotic, leftover, dice, _ly, 9178' -> 'No'). \"\n",
        "#context = \"is there a rough, overarching theme tying most (i.e., >40%) of the following tokens together? We are using the term “theme” generously here — for example, if most of the outputs are numbers with no discernable pattern, then output “Yes: numbers”. This could also be a more broad one such as “religion”. There could also be two semantic meanings of a word that are both captured by the model — in this case, please provide both meanings.Please give your answer in the format 'Yes: (insert less than 4 word summary of concept)' or 'No', with no explanation.\"\n",
        "def get_interpretability(act_prompts):\n",
        "    interpretable_neurons = {}\n",
        "    flag = False\n",
        "    print(len(act_prompts.keys()))\n",
        "    for neur in act_prompts.keys():\n",
        "        print(neur)\n",
        "        token_string = \": \"\n",
        "        for key in act_prompts[neur].keys():\n",
        "            for token in act_prompts[neur][key]:\n",
        "                token_string = token_string + \", \" + token\n",
        "                if len(encoding.encode(context + token_string)) > 4050:\n",
        "                    flag = True\n",
        "                    break\n",
        "            if flag:\n",
        "              flag = False\n",
        "              break\n",
        "        #print(len(encoding.encode(context + token_string)))\n",
        "        response = openai.ChatCompletion.create(\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "          messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": context + token_string},\n",
        "            ]\n",
        "        )\n",
        "        interpretation = response['choices'][0]['message']['content']\n",
        "        #print(token_string)\n",
        "        #print(interpretation)\n",
        "       # if \"I'm sorry\" in interpretation:\n",
        "           # print(token_string)\n",
        "        if \"Yes\" in interpretation:\n",
        "           # print(interpretation[4:])\n",
        "            interpretable_neurons[neur] = interpretation[4:]\n",
        "\n",
        "    return interpretable_neurons"
      ],
      "metadata": {
        "id": "IaBvzrR3x5T-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "\n",
        "interpretable_neurons = get_interpretability(obj)\n",
        "\n",
        "#a = {'hello': 'world'}\n",
        "\n",
        "with open('interpretable_neurons.pkl', 'wb') as handle:\n",
        "    pkl.dump(interpretable_neurons, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('interpretable_neurons.pkl', 'rb') as handle:\n",
        "    b = pkl.load(handle)\n",
        "\n",
        "print(interpretable_neurons == b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbPP9_J4yNM9",
        "outputId": "ee3f20f3-5e29-40ec-a047-3dcf741df649"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "298\n",
            "5\n",
            "10\n",
            "20\n",
            "21\n",
            "42\n",
            "46\n",
            "51\n",
            "52\n",
            "60\n",
            "88\n",
            "115\n",
            "131\n",
            "156\n",
            "171\n",
            "178\n",
            "180\n",
            "188\n",
            "201\n",
            "202\n",
            "208\n",
            "233\n",
            "250\n",
            "253\n",
            "256\n",
            "265\n",
            "316\n",
            "317\n",
            "319\n",
            "325\n",
            "331\n",
            "335\n",
            "344\n",
            "356\n",
            "361\n",
            "365\n",
            "379\n",
            "381\n",
            "407\n",
            "415\n",
            "428\n",
            "442\n",
            "452\n",
            "468\n",
            "489\n",
            "500\n",
            "519\n",
            "520\n",
            "560\n",
            "583\n",
            "621\n",
            "628\n",
            "661\n",
            "674\n",
            "681\n",
            "682\n",
            "691\n",
            "699\n",
            "709\n",
            "735\n",
            "736\n",
            "776\n",
            "787\n",
            "789\n",
            "805\n",
            "830\n",
            "833\n",
            "835\n",
            "841\n",
            "846\n",
            "853\n",
            "854\n",
            "871\n",
            "888\n",
            "890\n",
            "893\n",
            "900\n",
            "912\n",
            "922\n",
            "931\n",
            "935\n",
            "943\n",
            "956\n",
            "981\n",
            "982\n",
            "999\n",
            "1012\n",
            "1026\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1059\n",
            "1060\n",
            "1075\n",
            "1096\n",
            "1113\n",
            "1127\n",
            "1134\n",
            "1198\n",
            "1201\n",
            "1202\n",
            "1204\n",
            "1214\n",
            "1216\n",
            "1236\n",
            "1246\n",
            "1256\n",
            "1293\n",
            "1302\n",
            "1311\n",
            "1313\n",
            "1340\n",
            "1359\n",
            "1364\n",
            "1366\n",
            "1381\n",
            "1387\n",
            "1393\n",
            "1419\n",
            "1426\n",
            "1432\n",
            "1434\n",
            "1439\n",
            "1447\n",
            "1470\n",
            "1472\n",
            "1473\n",
            "1484\n",
            "1496\n",
            "1507\n",
            "1515\n",
            "1530\n",
            "1539\n",
            "1550\n",
            "1559\n",
            "1567\n",
            "1569\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1594\n",
            "1595\n",
            "1615\n",
            "1616\n",
            "1625\n",
            "1633\n",
            "1642\n",
            "1646\n",
            "1647\n",
            "1650\n",
            "1657\n",
            "1669\n",
            "1673\n",
            "1679\n",
            "1703\n",
            "1711\n",
            "1734\n",
            "1751\n",
            "1754\n",
            "1755\n",
            "1758\n",
            "1759\n",
            "1766\n",
            "1771\n",
            "1785\n",
            "1786\n",
            "1787\n",
            "1802\n",
            "1808\n",
            "1821\n",
            "1828\n",
            "1833\n",
            "1837\n",
            "1854\n",
            "1855\n",
            "1901\n",
            "1910\n",
            "1911\n",
            "1919\n",
            "1933\n",
            "1936\n",
            "1947\n",
            "1951\n",
            "1958\n",
            "1968\n",
            "1977\n",
            "1985\n",
            "1989\n",
            "1999\n",
            "2002\n",
            "2010\n",
            "2021\n",
            "2029\n",
            "2037\n",
            "2052\n",
            "2060\n",
            "2064\n",
            "2068\n",
            "2070\n",
            "2071\n",
            "2073\n",
            "2075\n",
            "2089\n",
            "2097\n",
            "2102\n",
            "2117\n",
            "2119\n",
            "2123\n",
            "2126\n",
            "2146\n",
            "2149\n",
            "2156\n",
            "2166\n",
            "2169\n",
            "2212\n",
            "2213\n",
            "2218\n",
            "2225\n",
            "2228\n",
            "2231\n",
            "2244\n",
            "2262\n",
            "2270\n",
            "2288\n",
            "2299\n",
            "2309\n",
            "2330\n",
            "2347\n",
            "2351\n",
            "2352\n",
            "2357\n",
            "2360\n",
            "2367\n",
            "2381\n",
            "2385\n",
            "2390\n",
            "2424\n",
            "2443\n",
            "2445\n",
            "2448\n",
            "2451\n",
            "2469\n",
            "2472\n",
            "2476\n",
            "2477\n",
            "2496\n",
            "2500\n",
            "2513\n",
            "2554\n",
            "2582\n",
            "2602\n",
            "2603\n",
            "2618\n",
            "2651\n",
            "2662\n",
            "2676\n",
            "2677\n",
            "2690\n",
            "2691\n",
            "2703\n",
            "2711\n",
            "2713\n",
            "2715\n",
            "2719\n",
            "2725\n",
            "2735\n",
            "2739\n",
            "2752\n",
            "2765\n",
            "2782\n",
            "2804\n",
            "2810\n",
            "2814\n",
            "2828\n",
            "2831\n",
            "2837\n",
            "2858\n",
            "2861\n",
            "2862\n",
            "2864\n",
            "2865\n",
            "2891\n",
            "2899\n",
            "2905\n",
            "2918\n",
            "2937\n",
            "2938\n",
            "2945\n",
            "2965\n",
            "2978\n",
            "2980\n",
            "2992\n",
            "3014\n",
            "3015\n",
            "3027\n",
            "3031\n",
            "3037\n",
            "3057\n",
            "3066\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(interpretable_neurons.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ijFmJr7btol",
        "outputId": "b36ac596-6754-4c75-ff1a-c2302a55b5bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpretable_neurons[361]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MQlelZncbzdY",
        "outputId": "e074bd43-f7fe-4922-bd3a-02d2f6460a3c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Civil Rights, Protestants, Silk Road.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}